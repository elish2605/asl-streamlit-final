{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Install Streamlit library"
      ],
      "metadata": {
        "id": "-Lxwa0w_v_5K"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ph83DoaVv7Iz"
      },
      "outputs": [],
      "source": [
        "!pip install -q streamlit"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class_names=['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'del', 'nothing', 'space']"
      ],
      "metadata": {
        "id": "oYJp5dnIyxo-"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save Streamlit app code\n",
        "streamlit_script = \"\"\"\n",
        "import streamlit as st\n",
        "import torch\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "import os\n",
        "from torchvision import models\n",
        "import torch.nn as nn\n",
        "\n",
        "# ---- Model Definition ----\n",
        "class ASLResNet101(nn.Module):\n",
        "    def __init__(self, num_classes=29):\n",
        "        super(ASLResNet101, self).__init__()\n",
        "        self.backbone = models.resnet101(weights=models.ResNet101_Weights.DEFAULT)\n",
        "        num_ftrs = self.backbone.fc.in_features\n",
        "        self.backbone.fc = nn.Linear(num_ftrs, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.backbone(x)\n",
        "\n",
        "# ---- Load Model ----\n",
        "def load_model(model_path):\n",
        "    model = ASLResNet101(num_classes=29)\n",
        "    model = torch.load(model_path, weights_only=False)\n",
        "    model.eval()\n",
        "    return model\n",
        "\n",
        "# ---- Image Preprocessing ----\n",
        "def preprocess_image(image):\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Resize((128, 128)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                             std=[0.229, 0.224, 0.225])\n",
        "    ])\n",
        "    image = image.convert('RGB')\n",
        "    return transform(image).unsqueeze(0)\n",
        "\n",
        "# ---- Predict ----\n",
        "def predict(model, image_tensor, class_names):\n",
        "    with torch.no_grad():\n",
        "        outputs = model(image_tensor)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "    return class_names[predicted.item()]\n",
        "\n",
        "# ---- Streamlit UI ----\n",
        "st.title(\"ASL Image Sequence Predictor\")\n",
        "\n",
        "show_images = st.checkbox(\"Show uploaded images\", value=False)\n",
        "uploaded_files = st.file_uploader(\"Upload ASL letter images in order\", type=[\"jpg\", \"jpeg\", \"png\"], accept_multiple_files=True)\n",
        "\n",
        "model_path = os.path.join(\"/content\", \"asl_resnet_model.pt\")\n",
        "class_names = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'del', 'nothing', 'space']\n",
        "model = load_model(model_path)\n",
        "\n",
        "if uploaded_files:\n",
        "    predictions = []\n",
        "\n",
        "    for uploaded_file in uploaded_files:\n",
        "        image = Image.open(uploaded_file)\n",
        "        image_tensor = preprocess_image(image)\n",
        "        prediction = predict(model, image_tensor, class_names)\n",
        "        predictions.append(prediction)\n",
        "\n",
        "    # Show images if checked\n",
        "    if show_images:\n",
        "        cols = st.columns(len(uploaded_files))\n",
        "        for idx, uploaded_file in enumerate(uploaded_files):\n",
        "            image = Image.open(uploaded_file)\n",
        "            with cols[idx]:\n",
        "                st.image(image, use_column_width=True)\n",
        "\n",
        "    # Display predictions inline\n",
        "    st.markdown(\"### 🔤\")\n",
        "    st.markdown(\" \".join(predictions))\n",
        "\"\"\"\n"
      ],
      "metadata": {
        "id": "qIZZCEOrVpYJ"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save to file\n",
        "with open(\"asl_streamlit_app.py\", \"w\") as f:\n",
        "    f.write(streamlit_script)"
      ],
      "metadata": {
        "id": "XXdN78xRVtCv"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!npm install localtunnel"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RcMnUh5MV4Rd",
        "outputId": "95f2cde6-4491-42d6-9e46-29c12ddc1ea9"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0K⠹\u001b[1G\u001b[0K⠸\u001b[1G\u001b[0K⠼\u001b[1G\u001b[0K⠴\u001b[1G\u001b[0K⠦\u001b[1G\u001b[0K⠧\u001b[1G\u001b[0K⠇\u001b[1G\u001b[0K⠏\u001b[1G\u001b[0K⠋\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0K⠹\u001b[1G\u001b[0K⠸\u001b[1G\u001b[0K⠼\u001b[1G\u001b[0K⠴\u001b[1G\u001b[0K⠦\u001b[1G\u001b[0K⠧\u001b[1G\u001b[0K⠇\u001b[1G\u001b[0K⠏\u001b[1G\u001b[0K⠋\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0K⠹\u001b[1G\u001b[0K⠸\u001b[1G\u001b[0K⠼\u001b[1G\u001b[0K⠴\u001b[1G\u001b[0K⠦\u001b[1G\u001b[0K⠧\u001b[1G\u001b[0K⠇\u001b[1G\u001b[0K⠏\u001b[1G\u001b[0K\n",
            "added 22 packages in 3s\n",
            "\u001b[1G\u001b[0K⠏\u001b[1G\u001b[0K\n",
            "\u001b[1G\u001b[0K⠏\u001b[1G\u001b[0K3 packages are looking for funding\n",
            "\u001b[1G\u001b[0K⠏\u001b[1G\u001b[0K  run `npm fund` for details\n",
            "\u001b[1G\u001b[0K⠏\u001b[1G\u001b[0K"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !streamlit run app.py &>/content/logs.txt &>/content/logs.txt & npx localtunnel --port 8501 & wget -q -O - https://loca.lt/mytunnelpassword"
      ],
      "metadata": {
        "id": "1uMI0WUaV5TT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!streamlit run asl_streamlit_app.py &>/content/logs.txt &>/content/logs.txt & npx localtunnel --port 8501 & wget -q -O - https://loca.lt/mytunnelpassword"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nil1TWHPXuGP",
        "outputId": "37ac397b-2d36-425c-ebb0-1f919dec93f3"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0K34.81.137.24your url is: https://great-facts-stand.loca.lt\n",
            "/content/node_modules/localtunnel/bin/lt.js:81\n",
            "    throw err;\n",
            "    ^\n",
            "\n",
            "Error: connection refused: localtunnel.me:13929 (check your firewall settings)\n",
            "    at Socket.<anonymous> \u001b[90m(/content/\u001b[39mnode_modules/\u001b[4mlocaltunnel\u001b[24m/lib/TunnelCluster.js:52:11\u001b[90m)\u001b[39m\n",
            "\u001b[90m    at Socket.emit (node:events:524:28)\u001b[39m\n",
            "\u001b[90m    at emitErrorNT (node:internal/streams/destroy:169:8)\u001b[39m\n",
            "\u001b[90m    at emitErrorCloseNT (node:internal/streams/destroy:128:3)\u001b[39m\n",
            "\u001b[90m    at process.processTicksAndRejections (node:internal/process/task_queues:82:21)\u001b[39m\n",
            "\n",
            "Node.js v20.19.0\n",
            "\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0K"
          ]
        }
      ]
    }
  ]
}